import streamlit as st
import openai

# --- UI è®¾ç½® ---
st.set_page_config(page_title="Trae AI Chat", page_icon="ğŸ¤–")
st.title("ğŸ¤– æ¨å¨çš„ç‰©ç†è¯¾å ‚æœºå™¨äºº")

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("è®¾ç½®")
    
    # API Key è¾“å…¥
    api_key = st.text_input("è¾“å…¥ä½ çš„ API Key", type="password", help="ä» OpenAI æˆ– DeepSeek å®˜ç½‘è·å–", value="sk-bb20c47e022b4d299a4077932081b872")
    
    # æ¨¡å‹é€‰æ‹©
    model_options = ["gpt-4o", "deepseek-chat"]
    selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹", model_options, index=1)
    
    st.markdown("---")
    st.markdown("ä¸çŸ¥é“å¦‚ä½•è·å– API Keyï¼Ÿ")
    st.page_link("https://platform.openai.com/api-keys", label="OpenAI API Key", icon="ğŸ”‘")
    st.page_link("https://platform.deepseek.com/api_keys", label="DeepSeek API Key", icon="ğŸ”‘")

# --- API Client åˆå§‹åŒ– ---
def get_openai_client(api_key, model):
    if not api_key:
        return None
    
    base_url = None
    # ä¸º DeepSeek æ¨¡å‹è®¾ç½®ç‰¹å®šçš„ base_url
    if model == "deepseek-chat":
        base_url = "https://api.deepseek.com/v1"
    
    try:
        return openai.OpenAI(api_key=api_key, base_url=base_url)
    except Exception as e:
        st.error(f"åˆ›å»º API Client å¤±è´¥: {e}")
        return None

client = get_openai_client(api_key, selected_model)

# --- èŠå¤©è®°å½•ç®¡ç† ---
# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- èŠå¤©è¾“å…¥å’Œå“åº” ---
if prompt := st.chat_input("ä½ å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"):
    # æ£€æŸ¥ API Key æ˜¯å¦å·²è¾“å…¥
    if not client:
        st.warning("è¯·è¾“å…¥ä½ çš„ API Keyã€‚")
        st.stop()

    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•å¹¶æ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ˜¾ç¤ºåŠ©æ‰‹çš„å“åº”
    with st.chat_message("assistant"):
        try:
            # å®šä¹‰æµå¼å“åº”ç”Ÿæˆå™¨
            def stream_generator():
                stream = client.chat.completions.create(
                    model=selected_model,
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in st.session_state.messages
                    ],
                    stream=True,
                )
                for chunk in stream:
                    content = chunk.choices[0].delta.content
                    if content:
                        yield content

            # ä½¿ç”¨ st.write_stream æ¥ä¼˜é›…åœ°å¤„ç†æµå¼è¾“å‡º
            response = st.write_stream(stream_generator)
            
            # å°†å®Œæ•´çš„åŠ©æ‰‹å“åº”æ·»åŠ åˆ°èŠå¤©è®°å½•
            st.session_state.messages.append({"role": "assistant", "content": response})

        except openai.APIConnectionError as e:
            st.error(f"API è¿æ¥é”™è¯¯: {e.__cause__}")
        except openai.RateLimitError:
            st.error("API è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
        except openai.APIStatusError as e:
            st.error(f"API çŠ¶æ€é”™è¯¯: {e.status_code} - {e.response}")
        except Exception as e:
            st.error(f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")